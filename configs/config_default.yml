model: 'geonet'
# numbers of lgab module, keep default when you first use this network
task: 'pred'
#task: 'prec'
downstage: 2
n_lgab: 3
# channel of lgab module, keep default when you first use this network
c_lgan: 3
# the size of SWA and WA
window_sizes: [ 1,1,1 ]
#down_sample
down_sample: 720
# expand channels in FD
r_expand: 4

# float number precision, 16 32 64, keep the default
fp: 32
#loss function, SmoothL1Loss L1Loss are optional
loss: 'nn.SmoothL1Loss'
#loss: 'nn.L1Loss()'
optimizer: 'AdamW'
# if you set the pretrain model, this program will train the model from the model.
# if you want to train the model from zero, please keep the path to none
pretrain:
# resume train from the specific path
resume:
## parameters for model training
# the number of a batch
batch_size: 2
balanced_gpu0: -1
# the epochs of training
epochs: 100
# the initial learning rate
lr: 0.0002
# the decay epochs of the learning rate. more details can refer the paper
decays: [ 50,80,90,95 ]
# keep the default
gamma: 0.5
# test log each time
test_every: 1
# the lines in one epoch to print
log_lines: 10
# the path to restore the log file
log_path: "./experiments"
# the name of log file, you can keep default if you don`t set this parameter
log_name:
# turn on cloudlog
cloudlog: off
# repeat the training dataset
repeat: 1
# augment the input data
augment: 'off'

# produce
# specify the path of model to produce the results
model_path:
# save path
save_path: "./proc"

## hardware specification
# specify the GPUs you want to use. [0] means using the first GPU. [1,3] means using second and fourth GPU
gpu_ids: [ 0 ]
# threads to work, 16 is reasonable
threads: 0
## data specification
# the path train and test dateset. You can download the dataset in this project
pred_data_path: 'npy'
prec_data_path: 'prec'
